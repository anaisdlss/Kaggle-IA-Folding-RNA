{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5d3f0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "701e70c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>experiment_type</th>\n",
       "      <th>signal_to_noise</th>\n",
       "      <th>reactivity_0001</th>\n",
       "      <th>reactivity_0002</th>\n",
       "      <th>reactivity_0003</th>\n",
       "      <th>reactivity_0004</th>\n",
       "      <th>reactivity_0005</th>\n",
       "      <th>reactivity_0006</th>\n",
       "      <th>reactivity_0007</th>\n",
       "      <th>...</th>\n",
       "      <th>reactivity_0197</th>\n",
       "      <th>reactivity_0198</th>\n",
       "      <th>reactivity_0199</th>\n",
       "      <th>reactivity_0200</th>\n",
       "      <th>reactivity_0201</th>\n",
       "      <th>reactivity_0202</th>\n",
       "      <th>reactivity_0203</th>\n",
       "      <th>reactivity_0204</th>\n",
       "      <th>reactivity_0205</th>\n",
       "      <th>reactivity_0206</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAAGAUAUGGAUCGGCCAUCGAU...</td>\n",
       "      <td>DMS_MaP</td>\n",
       "      <td>2.711</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAAUGAUUUUGACACAUGGUUUA...</td>\n",
       "      <td>DMS_MaP</td>\n",
       "      <td>4.427</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAAGGUGUCUGGACUAGAGGCUG...</td>\n",
       "      <td>DMS_MaP</td>\n",
       "      <td>1.981</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAACAUCUUUGCUUGGCAGCAUA...</td>\n",
       "      <td>DMS_MaP</td>\n",
       "      <td>34.976</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAACAACUAUGUACGUCAAGUAA...</td>\n",
       "      <td>DMS_MaP</td>\n",
       "      <td>2.051</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 209 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sequence experiment_type  \\\n",
       "0  GGGAACGACUCGAGUAGAGUCGAAAAGAUAUGGAUCGGCCAUCGAU...         DMS_MaP   \n",
       "1  GGGAACGACUCGAGUAGAGUCGAAAAUGAUUUUGACACAUGGUUUA...         DMS_MaP   \n",
       "2  GGGAACGACUCGAGUAGAGUCGAAAAGGUGUCUGGACUAGAGGCUG...         DMS_MaP   \n",
       "3  GGGAACGACUCGAGUAGAGUCGAAAACAUCUUUGCUUGGCAGCAUA...         DMS_MaP   \n",
       "4  GGGAACGACUCGAGUAGAGUCGAAAACAACUAUGUACGUCAAGUAA...         DMS_MaP   \n",
       "\n",
       "   signal_to_noise  reactivity_0001  reactivity_0002  reactivity_0003  \\\n",
       "0            2.711              NaN              NaN              NaN   \n",
       "1            4.427              NaN              NaN              NaN   \n",
       "2            1.981              NaN              NaN              NaN   \n",
       "3           34.976              NaN              NaN              NaN   \n",
       "4            2.051              NaN              NaN              NaN   \n",
       "\n",
       "   reactivity_0004  reactivity_0005  reactivity_0006  reactivity_0007  ...  \\\n",
       "0              NaN              NaN              NaN              NaN  ...   \n",
       "1              NaN              NaN              NaN              NaN  ...   \n",
       "2              NaN              NaN              NaN              NaN  ...   \n",
       "3              NaN              NaN              NaN              NaN  ...   \n",
       "4              NaN              NaN              NaN              NaN  ...   \n",
       "\n",
       "   reactivity_0197  reactivity_0198  reactivity_0199  reactivity_0200  \\\n",
       "0              NaN              NaN              NaN              NaN   \n",
       "1              NaN              NaN              NaN              NaN   \n",
       "2              NaN              NaN              NaN              NaN   \n",
       "3              NaN              NaN              NaN              NaN   \n",
       "4              NaN              NaN              NaN              NaN   \n",
       "\n",
       "   reactivity_0201  reactivity_0202  reactivity_0203  reactivity_0204  \\\n",
       "0              NaN              NaN              NaN              NaN   \n",
       "1              NaN              NaN              NaN              NaN   \n",
       "2              NaN              NaN              NaN              NaN   \n",
       "3              NaN              NaN              NaN              NaN   \n",
       "4              NaN              NaN              NaN              NaN   \n",
       "\n",
       "   reactivity_0205  reactivity_0206  \n",
       "0              NaN              NaN  \n",
       "1              NaN              NaN  \n",
       "2              NaN              NaN  \n",
       "3              NaN              NaN  \n",
       "4              NaN              NaN  \n",
       "\n",
       "[5 rows x 209 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('df_train_filtered.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e091074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>experiment_type</th>\n",
       "      <th>signal_to_noise</th>\n",
       "      <th>reactivity_0001</th>\n",
       "      <th>reactivity_0002</th>\n",
       "      <th>reactivity_0003</th>\n",
       "      <th>reactivity_0004</th>\n",
       "      <th>reactivity_0005</th>\n",
       "      <th>reactivity_0006</th>\n",
       "      <th>reactivity_0007</th>\n",
       "      <th>...</th>\n",
       "      <th>reactivity_0197</th>\n",
       "      <th>reactivity_0198</th>\n",
       "      <th>reactivity_0199</th>\n",
       "      <th>reactivity_0200</th>\n",
       "      <th>reactivity_0201</th>\n",
       "      <th>reactivity_0202</th>\n",
       "      <th>reactivity_0203</th>\n",
       "      <th>reactivity_0204</th>\n",
       "      <th>reactivity_0205</th>\n",
       "      <th>reactivity_0206</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAACUUAAAUCUGCUACGUGUAU...</td>\n",
       "      <td>2A3_MaP</td>\n",
       "      <td>3.389</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAAGCUCUUGCCAUCCUCUCGGU...</td>\n",
       "      <td>2A3_MaP</td>\n",
       "      <td>2.147</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAACGGGAACAAGGCAUGCUUAA...</td>\n",
       "      <td>DMS_MaP</td>\n",
       "      <td>5.380</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAAGAUAUGGACAUCGAAGAACA...</td>\n",
       "      <td>DMS_MaP</td>\n",
       "      <td>1.388</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAAGUCUGAGGCCUCAAAUGGAC...</td>\n",
       "      <td>2A3_MaP</td>\n",
       "      <td>2.808</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 209 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sequence experiment_type  \\\n",
       "0  GGGAACGACUCGAGUAGAGUCGAAAACUUAAAUCUGCUACGUGUAU...         2A3_MaP   \n",
       "1  GGGAACGACUCGAGUAGAGUCGAAAAGCUCUUGCCAUCCUCUCGGU...         2A3_MaP   \n",
       "2  GGGAACGACUCGAGUAGAGUCGAAAACGGGAACAAGGCAUGCUUAA...         DMS_MaP   \n",
       "3  GGGAACGACUCGAGUAGAGUCGAAAAGAUAUGGACAUCGAAGAACA...         DMS_MaP   \n",
       "4  GGGAACGACUCGAGUAGAGUCGAAAAGUCUGAGGCCUCAAAUGGAC...         2A3_MaP   \n",
       "\n",
       "   signal_to_noise  reactivity_0001  reactivity_0002  reactivity_0003  \\\n",
       "0            3.389              NaN              NaN              NaN   \n",
       "1            2.147              NaN              NaN              NaN   \n",
       "2            5.380              NaN              NaN              NaN   \n",
       "3            1.388              NaN              NaN              NaN   \n",
       "4            2.808              NaN              NaN              NaN   \n",
       "\n",
       "   reactivity_0004  reactivity_0005  reactivity_0006  reactivity_0007  ...  \\\n",
       "0              NaN              NaN              NaN              NaN  ...   \n",
       "1              NaN              NaN              NaN              NaN  ...   \n",
       "2              NaN              NaN              NaN              NaN  ...   \n",
       "3              NaN              NaN              NaN              NaN  ...   \n",
       "4              NaN              NaN              NaN              NaN  ...   \n",
       "\n",
       "   reactivity_0197  reactivity_0198  reactivity_0199  reactivity_0200  \\\n",
       "0              NaN              NaN              NaN              NaN   \n",
       "1              NaN              NaN              NaN              NaN   \n",
       "2              NaN              NaN              NaN              NaN   \n",
       "3              NaN              NaN              NaN              NaN   \n",
       "4              NaN              NaN              NaN              NaN   \n",
       "\n",
       "   reactivity_0201  reactivity_0202  reactivity_0203  reactivity_0204  \\\n",
       "0              NaN              NaN              NaN              NaN   \n",
       "1              NaN              NaN              NaN              NaN   \n",
       "2              NaN              NaN              NaN              NaN   \n",
       "3              NaN              NaN              NaN              NaN   \n",
       "4              NaN              NaN              NaN              NaN   \n",
       "\n",
       "   reactivity_0205  reactivity_0206  \n",
       "0              NaN              NaN  \n",
       "1              NaN              NaN  \n",
       "2              NaN              NaN  \n",
       "3              NaN              NaN  \n",
       "4              NaN              NaN  \n",
       "\n",
       "[5 rows x 209 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val = pd.read_csv('df_val_filtered.csv')\n",
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cf912a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>experiment_type</th>\n",
       "      <th>signal_to_noise</th>\n",
       "      <th>reactivity_0001</th>\n",
       "      <th>reactivity_0002</th>\n",
       "      <th>reactivity_0003</th>\n",
       "      <th>reactivity_0004</th>\n",
       "      <th>reactivity_0005</th>\n",
       "      <th>reactivity_0006</th>\n",
       "      <th>reactivity_0007</th>\n",
       "      <th>...</th>\n",
       "      <th>reactivity_0197</th>\n",
       "      <th>reactivity_0198</th>\n",
       "      <th>reactivity_0199</th>\n",
       "      <th>reactivity_0200</th>\n",
       "      <th>reactivity_0201</th>\n",
       "      <th>reactivity_0202</th>\n",
       "      <th>reactivity_0203</th>\n",
       "      <th>reactivity_0204</th>\n",
       "      <th>reactivity_0205</th>\n",
       "      <th>reactivity_0206</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAAGAUAUGGACGAGCGAUAAGC...</td>\n",
       "      <td>DMS_MaP</td>\n",
       "      <td>2.057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAAGCUUAAGGAUUGUGUUAUGU...</td>\n",
       "      <td>2A3_MaP</td>\n",
       "      <td>1.265</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAAACAAGGCAAACGUGAUGGGG...</td>\n",
       "      <td>2A3_MaP</td>\n",
       "      <td>7.185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAAGAUAUGGAAUUCCACGAGGU...</td>\n",
       "      <td>DMS_MaP</td>\n",
       "      <td>1.458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAAGAUAUGGAAUAGUUCUGCUC...</td>\n",
       "      <td>2A3_MaP</td>\n",
       "      <td>4.642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 209 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sequence experiment_type  \\\n",
       "0  GGGAACGACUCGAGUAGAGUCGAAAAGAUAUGGACGAGCGAUAAGC...         DMS_MaP   \n",
       "1  GGGAACGACUCGAGUAGAGUCGAAAAGCUUAAGGAUUGUGUUAUGU...         2A3_MaP   \n",
       "2  GGGAACGACUCGAGUAGAGUCGAAAAACAAGGCAAACGUGAUGGGG...         2A3_MaP   \n",
       "3  GGGAACGACUCGAGUAGAGUCGAAAAGAUAUGGAAUUCCACGAGGU...         DMS_MaP   \n",
       "4  GGGAACGACUCGAGUAGAGUCGAAAAGAUAUGGAAUAGUUCUGCUC...         2A3_MaP   \n",
       "\n",
       "   signal_to_noise  reactivity_0001  reactivity_0002  reactivity_0003  \\\n",
       "0            2.057              NaN              NaN              NaN   \n",
       "1            1.265              NaN              NaN              NaN   \n",
       "2            7.185              NaN              NaN              NaN   \n",
       "3            1.458              NaN              NaN              NaN   \n",
       "4            4.642              NaN              NaN              NaN   \n",
       "\n",
       "   reactivity_0004  reactivity_0005  reactivity_0006  reactivity_0007  ...  \\\n",
       "0              NaN              NaN              NaN              NaN  ...   \n",
       "1              NaN              NaN              NaN              NaN  ...   \n",
       "2              NaN              NaN              NaN              NaN  ...   \n",
       "3              NaN              NaN              NaN              NaN  ...   \n",
       "4              NaN              NaN              NaN              NaN  ...   \n",
       "\n",
       "   reactivity_0197  reactivity_0198  reactivity_0199  reactivity_0200  \\\n",
       "0              NaN              NaN              NaN              NaN   \n",
       "1              NaN              NaN              NaN              NaN   \n",
       "2              NaN              NaN              NaN              NaN   \n",
       "3              NaN              NaN              NaN              NaN   \n",
       "4              NaN              NaN              NaN              NaN   \n",
       "\n",
       "   reactivity_0201  reactivity_0202  reactivity_0203  reactivity_0204  \\\n",
       "0              NaN              NaN              NaN              NaN   \n",
       "1              NaN              NaN              NaN              NaN   \n",
       "2              NaN              NaN              NaN              NaN   \n",
       "3              NaN              NaN              NaN              NaN   \n",
       "4              NaN              NaN              NaN              NaN   \n",
       "\n",
       "   reactivity_0205  reactivity_0206  \n",
       "0              NaN              NaN  \n",
       "1              NaN              NaN  \n",
       "2              NaN              NaN  \n",
       "3              NaN              NaN  \n",
       "4              NaN              NaN  \n",
       "\n",
       "[5 rows x 209 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('df_test_filtered.csv')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80bbad86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def process_dataframe_fast(df, max_len=457):\n",
    "    \"\"\"\n",
    "    Version optimis√©e du traitement des s√©quences :\n",
    "    - One-hot encoding\n",
    "    - Normalisation robuste\n",
    "    - Padding\n",
    "    - Utilise un dictionnaire index√© plut√¥t que des filtres dans chaque boucle\n",
    "    \"\"\"\n",
    "    mapping = {'A':0, 'C':1, 'G':2, 'U':3}\n",
    "    factor = 1.4826\n",
    "    \n",
    "    # 1. Indexation des donn√©es pour acc√®s rapide\n",
    "    grouped = df.groupby(['sequence', 'experiment_type'])\n",
    "    dms_dict = {}\n",
    "    a3_dict = {}\n",
    "    \n",
    "    for (seq, exp), subdf in grouped:\n",
    "        row = subdf.iloc[0]\n",
    "        values = [row[f'reactivity_{i+1:04d}'] for i in range(len(seq))]\n",
    "        if exp == 'DMS_MaP':\n",
    "            dms_dict[seq] = np.array(values)\n",
    "        elif exp == '2A3_MaP':\n",
    "            a3_dict[seq] = np.array(values)\n",
    "    \n",
    "    unique_sequences = df['sequence'].unique()\n",
    "    \n",
    "    # 2. Pr√©-collecte des valeurs pour normalisation\n",
    "    dms_values = np.concatenate([v[~np.isnan(v)] for v in dms_dict.values() if v is not None])\n",
    "    a3_values  = np.concatenate([v[~np.isnan(v)] for v in a3_dict.values() if v is not None])\n",
    "    \n",
    "    dms_median = np.nanmedian(dms_values)\n",
    "    dms_mad    = np.nanmedian(np.abs(dms_values - dms_median))\n",
    "    a3_median  = np.nanmedian(a3_values)\n",
    "    a3_mad     = np.nanmedian(np.abs(a3_values - a3_median))\n",
    "    \n",
    "    print(f\"[INFO] DMS median={dms_median:.3f}, MAD={dms_mad:.3f}\")\n",
    "    print(f\"[INFO] 2A3 median={a3_median:.3f}, MAD={a3_mad:.3f}\")\n",
    "    \n",
    "    # 3. Cr√©ation du tensor par s√©quence\n",
    "    result_list = []\n",
    "    for seq in unique_sequences:\n",
    "        seq_len = len(seq)\n",
    "        tensor = np.zeros((max_len, 6), dtype=np.float32)\n",
    "        \n",
    "        # One-hot encoding rapide\n",
    "        for i, nuc in enumerate(seq):\n",
    "            if i >= max_len: break\n",
    "            if nuc in mapping:\n",
    "                tensor[i, mapping[nuc]] = 1\n",
    "        \n",
    "        # Ajout r√©activit√©s normalis√©es\n",
    "        dms_vals = dms_dict.get(seq, np.full(seq_len, np.nan))\n",
    "        a3_vals  = a3_dict.get(seq, np.full(seq_len, np.nan))\n",
    "        \n",
    "        if len(dms_vals) > 0:\n",
    "            dms_norm = np.nan_to_num((dms_vals - dms_median) / (factor * dms_mad))\n",
    "            tensor[:min(seq_len, max_len), 4] = dms_norm[:max_len]\n",
    "        if len(a3_vals) > 0:\n",
    "            a3_norm = np.nan_to_num((a3_vals - a3_median) / (factor * a3_mad))\n",
    "            tensor[:min(seq_len, max_len), 5] = a3_norm[:max_len]\n",
    "        \n",
    "        result_list.append(tensor)\n",
    "    \n",
    "    return result_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d6d946e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] DMS median=0.123, MAD=0.133\n",
      "[INFO] 2A3 median=0.212, MAD=0.212\n",
      "[INFO] DMS median=0.123, MAD=0.133\n",
      "[INFO] 2A3 median=0.213, MAD=0.213\n",
      "[INFO] DMS median=0.123, MAD=0.133\n",
      "[INFO] 2A3 median=0.213, MAD=0.213\n",
      "Train : 117591 s√©quences\n",
      "Test  : 20159 s√©quences\n",
      "Val   : 30238 s√©quences\n"
     ]
    }
   ],
   "source": [
    "# üü° 2. Transformation des trois jeux\n",
    "ohe_train_data = process_dataframe_fast(df_train)\n",
    "ohe_test_data  = process_dataframe_fast(df_test)\n",
    "ohe_val_data   = process_dataframe_fast(df_val)\n",
    "\n",
    "print(f\"Train : {len(ohe_train_data)} s√©quences\")\n",
    "print(f\"Test  : {len(ohe_test_data)} s√©quences\")\n",
    "print(f\"Val   : {len(ohe_val_data)} s√©quences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cce0e21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def split_X_Y(tensor_list):\n",
    "    \"\"\"\n",
    "    S√©pare X (features) et Y (targets) √† partir d'une liste de tableaux numpy.\n",
    "    Chaque tableau est de la forme (seq_len, 6) : 4 colonnes one-hot + 2 r√©activit√©s.\n",
    "    \n",
    "    Args:\n",
    "        tensor_list (list of np.ndarray): Liste de s√©quences trait√©es.\n",
    "    \n",
    "    Returns:\n",
    "        X: np.ndarray de shape (n_samples, seq_len, 4)\n",
    "        Y: np.ndarray de shape (n_samples, seq_len, 2)\n",
    "    \"\"\"\n",
    "    X_list = []\n",
    "    Y_list = []\n",
    "    \n",
    "    for tensor in tensor_list:\n",
    "        X_list.append(tensor[:, :4])  # 4 colonnes de one-hot\n",
    "        Y_list.append(tensor[:, 4:])  # 2 colonnes de r√©activit√©s normalis√©es\n",
    "    \n",
    "    X = np.stack(X_list)\n",
    "    Y = np.stack(Y_list)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44997e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (117591, 457, 4)\n",
      "Y_train: (117591, 457, 2)\n",
      "X_val: (30238, 457, 4)\n",
      "Y_val: (30238, 457, 2)\n",
      "X_test: (20159, 457, 4)\n",
      "Y_test: (20159, 457, 2)\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train = split_X_Y(ohe_train_data)\n",
    "X_val, Y_val = split_X_Y(ohe_val_data)\n",
    "X_test, Y_test = split_X_Y(ohe_test_data)\n",
    "\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"Y_train:\", Y_train.shape)\n",
    "print(\"X_val:\", X_val.shape)\n",
    "print(\"Y_val:\", Y_val.shape)\n",
    "print(\"X_test:\", X_test.shape)\n",
    "print(\"Y_test:\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbe1157b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ MPS activ√© : entra√Ænement sur GPU Apple Silicon\n",
      "Device utilis√© : mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"üöÄ MPS activ√© : entra√Ænement sur GPU Apple Silicon\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"‚ö†Ô∏è Pas de MPS d√©tect√©, fallback CPU\")\n",
    "\n",
    "print(f\"Device utilis√© : {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f34a40b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# M√©triques\n",
    "# -------------------------------\n",
    "def mae(y_pred, y_true):\n",
    "    return torch.mean(torch.abs(y_pred - y_true))\n",
    "\n",
    "def rmse(y_pred, y_true):\n",
    "    return torch.sqrt(torch.mean((y_pred - y_true)**2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1d10581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "class LstmPlusConv(nn.Module):\n",
    "    def __init__(self, input_size=(457, 4), output_size=2, hidden_size=64):\n",
    "        super().__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size[1], hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.lstm2 = nn.LSTM(hidden_size * 2, 32, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.conv1 = nn.Conv1d(32, 64, kernel_size=3, padding='same')\n",
    "        self.conv2 = nn.Conv1d(64, 128, kernel_size=3, padding='same', dilation=2)\n",
    "        self.conv3 = nn.Conv1d(128, 256, kernel_size=3, padding='same', dilation=4)\n",
    "        self.fc = nn.Linear(256, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm1(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x.transpose(1, 2)          # (batch, channels, seq_len)\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        x = x.transpose(1, 2)          # (batch, seq_len, channels)\n",
    "        x = self.fc(x)                 # (batch, seq_len, output_size)\n",
    "        return x\n",
    "# Exemple d'initialisation\n",
    "#model = LstmPlusConv(input_size=(457, 4), output_size=2, hidden_size=32).to(\"mps\")\n",
    "#print(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4eed018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Dataset factice (exemple)\n",
    "# -------------------------------\n",
    "batch_size = 128\n",
    "seq_len, feature_dim = 457, 4\n",
    "output_dim = 2\n",
    "num_samples = 128\n",
    "\n",
    "X_train_t = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "Y_train_t = torch.tensor(Y_train, dtype=torch.float32).to(device)\n",
    "\n",
    "X_val_t = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "Y_val_t = torch.tensor(Y_val, dtype=torch.float32).to(device)\n",
    "\n",
    "X_test_t = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "Y_test_t = torch.tensor(Y_test, dtype=torch.float32).to(device)\n",
    "\n",
    "# -------------------------------\n",
    "# 3Ô∏è‚É£ DataLoader\n",
    "# -------------------------------\n",
    "batch_size = 128\n",
    "train_dataset = TensorDataset(X_train_t, Y_train_t)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = TensorDataset(X_val_t, Y_val_t)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fcdae12",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TensorDataset(X_test_t, Y_test_t)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0fd27941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de batches train : 919\n",
      "Nombre de batches val   : 237\n"
     ]
    }
   ],
   "source": [
    "print(\"Nombre de batches train :\", len(train_loader))\n",
    "print(\"Nombre de batches val   :\", len(val_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adc5cc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (117591, 457, 4)\n",
      "Y_train shape: (117591, 457, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"Y_train shape:\", Y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14a67551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4Ô∏è‚É£ Masques pour ignore padding\n",
    "# -------------------------------\n",
    "def create_mask(y):\n",
    "    # True o√π les valeurs sont valides\n",
    "    return (y != 0).float()\n",
    "\n",
    "# -------------------------------\n",
    "# 5Ô∏è‚É£ Metrics masqu√©es\n",
    "# -------------------------------\n",
    "def masked_mse(y_pred, y_true):\n",
    "    mask = create_mask(y_true)\n",
    "    mse = ((y_pred - y_true) ** 2 * mask).sum() / mask.sum()\n",
    "    return mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6929fb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------------\n",
    "# Initialisation mod√®le, loss, optim\n",
    "# -------------------------------\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "model = LstmPlusConv().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=0.5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56ca1602",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 919/919 [02:00<00:00,  7.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] Train -> Loss: 1.2232, MAE: 0.3198, RMSE: 1.1033 | Val -> Loss: 1.0644, MAE: 0.2869, RMSE: 1.0309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 919/919 [01:59<00:00,  7.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50] Train -> Loss: 1.0500, MAE: 0.2880, RMSE: 1.0238 | Val -> Loss: 0.9869, MAE: 0.2789, RMSE: 0.9926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 919/919 [01:56<00:00,  7.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50] Train -> Loss: 0.9892, MAE: 0.2783, RMSE: 0.9937 | Val -> Loss: 0.9398, MAE: 0.2693, RMSE: 0.9686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 919/919 [01:43<00:00,  8.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50] Train -> Loss: 0.9534, MAE: 0.2707, RMSE: 0.9756 | Val -> Loss: 0.9177, MAE: 0.2616, RMSE: 0.9572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 919/919 [01:42<00:00,  8.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50] Train -> Loss: 0.9345, MAE: 0.2659, RMSE: 0.9659 | Val -> Loss: 0.9042, MAE: 0.2638, RMSE: 0.9501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 919/919 [01:46<00:00,  8.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50] Train -> Loss: 0.9213, MAE: 0.2632, RMSE: 0.9590 | Val -> Loss: 0.9066, MAE: 0.2566, RMSE: 0.9513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 919/919 [01:48<00:00,  8.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50] Train -> Loss: 0.9253, MAE: 0.2664, RMSE: 0.9609 | Val -> Loss: 0.8894, MAE: 0.2593, RMSE: 0.9423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 919/919 [01:48<00:00,  8.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50] Train -> Loss: 0.9055, MAE: 0.2600, RMSE: 0.9507 | Val -> Loss: 0.8853, MAE: 0.2568, RMSE: 0.9401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 919/919 [01:50<00:00,  8.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50] Train -> Loss: 0.8983, MAE: 0.2585, RMSE: 0.9470 | Val -> Loss: 0.8747, MAE: 0.2536, RMSE: 0.9345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 919/919 [01:51<00:00,  8.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50] Train -> Loss: 0.8909, MAE: 0.2573, RMSE: 0.9431 | Val -> Loss: 0.8705, MAE: 0.2565, RMSE: 0.9323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 919/919 [01:49<00:00,  8.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50] Train -> Loss: 0.8852, MAE: 0.2562, RMSE: 0.9400 | Val -> Loss: 0.8752, MAE: 0.2553, RMSE: 0.9348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 919/919 [01:45<00:00,  8.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50] Train -> Loss: 0.8804, MAE: 0.2553, RMSE: 0.9375 | Val -> Loss: 0.8602, MAE: 0.2541, RMSE: 0.9267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 919/919 [01:45<00:00,  8.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50] Train -> Loss: 0.8749, MAE: 0.2544, RMSE: 0.9346 | Val -> Loss: 0.8565, MAE: 0.2510, RMSE: 0.9247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 919/919 [01:54<00:00,  8.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50] Train -> Loss: 0.8714, MAE: 0.2539, RMSE: 0.9328 | Val -> Loss: 0.8531, MAE: 0.2505, RMSE: 0.9229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 919/919 [01:53<00:00,  8.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50] Train -> Loss: 0.8668, MAE: 0.2533, RMSE: 0.9303 | Val -> Loss: 0.8537, MAE: 0.2510, RMSE: 0.9233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 919/919 [01:52<00:00,  8.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50] Train -> Loss: 0.8633, MAE: 0.2530, RMSE: 0.9284 | Val -> Loss: 0.8688, MAE: 0.2512, RMSE: 0.9313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 919/919 [02:06<00:00,  7.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/50] Train -> Loss: 0.8594, MAE: 0.2524, RMSE: 0.9263 | Val -> Loss: 0.8450, MAE: 0.2506, RMSE: 0.9185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 919/919 [02:09<00:00,  7.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/50] Train -> Loss: 0.8729, MAE: 0.2588, RMSE: 0.9334 | Val -> Loss: 0.8507, MAE: 0.2530, RMSE: 0.9216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 919/919 [02:02<00:00,  7.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/50] Train -> Loss: 0.8576, MAE: 0.2528, RMSE: 0.9253 | Val -> Loss: 0.8476, MAE: 0.2515, RMSE: 0.9199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 919/919 [02:05<00:00,  7.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/50] Train -> Loss: 0.8518, MAE: 0.2513, RMSE: 0.9222 | Val -> Loss: 0.8419, MAE: 0.2487, RMSE: 0.9169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 919/919 [02:10<00:00,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/50] Train -> Loss: 0.8483, MAE: 0.2507, RMSE: 0.9203 | Val -> Loss: 0.8363, MAE: 0.2495, RMSE: 0.9138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 919/919 [02:06<00:00,  7.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/50] Train -> Loss: 0.8456, MAE: 0.2503, RMSE: 0.9188 | Val -> Loss: 0.8351, MAE: 0.2491, RMSE: 0.9132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 919/919 [02:10<00:00,  7.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/50] Train -> Loss: 0.8428, MAE: 0.2489, RMSE: 0.9173 | Val -> Loss: 0.8352, MAE: 0.2469, RMSE: 0.9133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 919/919 [02:08<00:00,  7.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/50] Train -> Loss: 0.8400, MAE: 0.2483, RMSE: 0.9157 | Val -> Loss: 0.8347, MAE: 0.2522, RMSE: 0.9130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 919/919 [02:10<00:00,  7.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/50] Train -> Loss: 0.8374, MAE: 0.2480, RMSE: 0.9143 | Val -> Loss: 0.8315, MAE: 0.2473, RMSE: 0.9112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 919/919 [02:05<00:00,  7.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/50] Train -> Loss: 0.8349, MAE: 0.2477, RMSE: 0.9130 | Val -> Loss: 0.8337, MAE: 0.2482, RMSE: 0.9124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 919/919 [02:08<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/50] Train -> Loss: 0.8333, MAE: 0.2474, RMSE: 0.9121 | Val -> Loss: 0.8281, MAE: 0.2456, RMSE: 0.9093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 919/919 [02:06<00:00,  7.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/50] Train -> Loss: 0.8306, MAE: 0.2471, RMSE: 0.9106 | Val -> Loss: 0.8299, MAE: 0.2456, RMSE: 0.9103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 919/919 [01:58<00:00,  7.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/50] Train -> Loss: 0.8289, MAE: 0.2468, RMSE: 0.9097 | Val -> Loss: 0.8257, MAE: 0.2463, RMSE: 0.9080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 919/919 [01:52<00:00,  8.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/50] Train -> Loss: 0.8262, MAE: 0.2465, RMSE: 0.9082 | Val -> Loss: 0.8225, MAE: 0.2440, RMSE: 0.9063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 919/919 [01:57<00:00,  7.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/50] Train -> Loss: 0.8239, MAE: 0.2463, RMSE: 0.9070 | Val -> Loss: 0.8213, MAE: 0.2433, RMSE: 0.9056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 919/919 [02:00<00:00,  7.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/50] Train -> Loss: 0.8223, MAE: 0.2461, RMSE: 0.9062 | Val -> Loss: 0.8206, MAE: 0.2455, RMSE: 0.9052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 919/919 [02:00<00:00,  7.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/50] Train -> Loss: 0.8203, MAE: 0.2458, RMSE: 0.9050 | Val -> Loss: 0.8207, MAE: 0.2451, RMSE: 0.9053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 919/919 [02:03<00:00,  7.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/50] Train -> Loss: 0.8185, MAE: 0.2456, RMSE: 0.9040 | Val -> Loss: 0.8167, MAE: 0.2454, RMSE: 0.9031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 919/919 [02:05<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/50] Train -> Loss: 0.8162, MAE: 0.2453, RMSE: 0.9027 | Val -> Loss: 0.8168, MAE: 0.2433, RMSE: 0.9031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 919/919 [02:03<00:00,  7.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/50] Train -> Loss: 0.8142, MAE: 0.2451, RMSE: 0.9016 | Val -> Loss: 0.8175, MAE: 0.2464, RMSE: 0.9036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 919/919 [02:04<00:00,  7.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/50] Train -> Loss: 0.8133, MAE: 0.2449, RMSE: 0.9011 | Val -> Loss: 0.8130, MAE: 0.2440, RMSE: 0.9010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 919/919 [02:05<00:00,  7.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/50] Train -> Loss: 0.8114, MAE: 0.2447, RMSE: 0.9001 | Val -> Loss: 0.8118, MAE: 0.2421, RMSE: 0.9003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 919/919 [02:06<00:00,  7.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/50] Train -> Loss: 0.8099, MAE: 0.2445, RMSE: 0.8993 | Val -> Loss: 0.8093, MAE: 0.2441, RMSE: 0.8990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 919/919 [02:14<00:00,  6.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/50] Train -> Loss: 0.8077, MAE: 0.2443, RMSE: 0.8980 | Val -> Loss: 0.8121, MAE: 0.2420, RMSE: 0.9005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 919/919 [02:09<00:00,  7.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/50] Train -> Loss: 0.8066, MAE: 0.2441, RMSE: 0.8974 | Val -> Loss: 0.8101, MAE: 0.2452, RMSE: 0.8994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 919/919 [02:19<00:00,  6.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/50] Train -> Loss: 0.8052, MAE: 0.2440, RMSE: 0.8966 | Val -> Loss: 0.8069, MAE: 0.2415, RMSE: 0.8976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 919/919 [02:10<00:00,  7.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/50] Train -> Loss: 0.8030, MAE: 0.2437, RMSE: 0.8953 | Val -> Loss: 0.8067, MAE: 0.2437, RMSE: 0.8975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 919/919 [02:12<00:00,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/50] Train -> Loss: 0.8023, MAE: 0.2437, RMSE: 0.8950 | Val -> Loss: 0.8092, MAE: 0.2434, RMSE: 0.8989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 919/919 [02:15<00:00,  6.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/50] Train -> Loss: 0.8009, MAE: 0.2435, RMSE: 0.8942 | Val -> Loss: 0.8050, MAE: 0.2420, RMSE: 0.8965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 919/919 [02:18<00:00,  6.65it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 48\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch_x, batch_y \u001b[38;5;129;01min\u001b[39;00m val_loader:\n\u001b[32m     47\u001b[39m     batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     outputs = model(batch_x)\n\u001b[32m     49\u001b[39m     loss = criterion(outputs, batch_y)\n\u001b[32m     51\u001b[39m     val_loss += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mLstmPlusConv.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     x, _ = \u001b[38;5;28mself\u001b[39m.lstm1(x)\n\u001b[32m     22\u001b[39m     x, _ = \u001b[38;5;28mself\u001b[39m.lstm2(x)\n\u001b[32m     23\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.dropout(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/torch/nn/modules/rnn.py:1127\u001b[39m, in \u001b[36mLSTM.forward\u001b[39m\u001b[34m(self, input, hx)\u001b[39m\n\u001b[32m   1124\u001b[39m         hx = \u001b[38;5;28mself\u001b[39m.permute_hidden(hx, sorted_indices)\n\u001b[32m   1126\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1127\u001b[39m     result = _VF.lstm(\n\u001b[32m   1128\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   1129\u001b[39m         hx,\n\u001b[32m   1130\u001b[39m         \u001b[38;5;28mself\u001b[39m._flat_weights,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m   1131\u001b[39m         \u001b[38;5;28mself\u001b[39m.bias,\n\u001b[32m   1132\u001b[39m         \u001b[38;5;28mself\u001b[39m.num_layers,\n\u001b[32m   1133\u001b[39m         \u001b[38;5;28mself\u001b[39m.dropout,\n\u001b[32m   1134\u001b[39m         \u001b[38;5;28mself\u001b[39m.training,\n\u001b[32m   1135\u001b[39m         \u001b[38;5;28mself\u001b[39m.bidirectional,\n\u001b[32m   1136\u001b[39m         \u001b[38;5;28mself\u001b[39m.batch_first,\n\u001b[32m   1137\u001b[39m     )\n\u001b[32m   1138\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1139\u001b[39m     result = _VF.lstm(\n\u001b[32m   1140\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   1141\u001b[39m         batch_sizes,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1148\u001b[39m         \u001b[38;5;28mself\u001b[39m.bidirectional,\n\u001b[32m   1149\u001b[39m     )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# -----------------------------------------\n",
    "# Boucle d'entra√Ænement compl√®te\n",
    "# -----------------------------------------\n",
    "num_epochs = 50\n",
    "patience = 5\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "history = {\n",
    "    \"train_loss\": [], \"train_mae\": [], \"train_rmse\": [],\n",
    "    \"val_loss\": [], \"val_mae\": [], \"val_rmse\": []\n",
    "}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # -----------------------------\n",
    "    # Phase d'entra√Ænement\n",
    "    # -----------------------------\n",
    "    model.train()\n",
    "    train_loss, train_mae, train_rmse_val = 0, 0, 0\n",
    "\n",
    "    for batch_x, batch_y in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\"):\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulation des m√©triques\n",
    "        train_loss += loss.item()\n",
    "        train_mae += mae(outputs, batch_y).item()\n",
    "        train_rmse_val += rmse(outputs, batch_y).item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    train_mae /= len(train_loader)\n",
    "    train_rmse_val /= len(train_loader)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Phase de validation\n",
    "    # -----------------------------\n",
    "    model.eval()\n",
    "    val_loss, val_mae, val_rmse_val = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in val_loader:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            val_mae += mae(outputs, batch_y).item()\n",
    "            val_rmse_val += rmse(outputs, batch_y).item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_mae /= len(val_loader)\n",
    "    val_rmse_val /= len(val_loader)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Scheduler & sauvegarde\n",
    "    # -----------------------------\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    history[\"train_loss\"].append(train_loss)\n",
    "    history[\"train_mae\"].append(train_mae)\n",
    "    history[\"train_rmse\"].append(train_rmse_val)\n",
    "\n",
    "    history[\"val_loss\"].append(val_loss)\n",
    "    history[\"val_mae\"].append(val_mae)\n",
    "    history[\"val_rmse\"].append(val_rmse_val)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Affichage des r√©sultats\n",
    "    # -----------------------------\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
    "          f\"Train -> Loss: {train_loss:.4f}, MAE: {train_mae:.4f}, RMSE: {train_rmse_val:.4f} | \"\n",
    "          f\"Val -> Loss: {val_loss:.4f}, MAE: {val_mae:.4f}, RMSE: {val_rmse_val:.4f}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Early stopping\n",
    "    # -----------------------------\n",
    "    if val_loss < best_val_loss - 1e-4:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        best_model_state = model.state_dict()\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"‚èπÔ∏è Early stopping triggered after {epoch+1} epochs.\")\n",
    "            break\n",
    "\n",
    "print(\"‚úÖ Entra√Ænement termin√©\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136f378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# -------------------------------\n",
    "# Fonction pour afficher les courbes d'entra√Ænement\n",
    "# -------------------------------\n",
    "def plot_training_history_torch(train_losses, val_losses, train_maes=None, val_maes=None,\n",
    "                                train_rmses=None, val_rmses=None):\n",
    "    # corps de la fonction inchang√©\n",
    "\n",
    "    \"\"\"\n",
    "    history : dictionnaire retourn√© par train_model_advanced\n",
    "              doit contenir au moins 'train_loss' et 'val_loss'\n",
    "              peut contenir 'train_mae', 'val_mae', 'train_rmse', 'val_rmse'\n",
    "    \"\"\"\n",
    "    metrics = ['Loss', 'MAE', 'RMSE']\n",
    "    fig_idx = 1\n",
    "    n_metrics = 1  # au moins la Loss\n",
    "    if 'train_mae' in history and 'val_mae' in history:\n",
    "        n_metrics += 1\n",
    "    if 'train_rmse' in history and 'val_rmse' in history:\n",
    "        n_metrics += 1\n",
    "\n",
    "    plt.figure(figsize=(6 * n_metrics, 5))\n",
    "    \n",
    "    # --- Loss ---\n",
    "    plt.subplot(1, n_metrics, fig_idx)\n",
    "    plt.plot(history['train_loss'], label='Train Loss', color='blue')\n",
    "    plt.plot(history['val_loss'], label='Val Loss', color='orange')\n",
    "    plt.title('Courbe de Loss (MSE)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    fig_idx += 1\n",
    "\n",
    "    # --- MAE ---\n",
    "    if 'train_mae' in history and 'val_mae' in history:\n",
    "        plt.subplot(1, n_metrics, fig_idx)\n",
    "        plt.plot(history['train_mae'], label='Train MAE', color='blue')\n",
    "        plt.plot(history['val_mae'], label='Val MAE', color='orange')\n",
    "        plt.title('Courbe de MAE')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('MAE')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        fig_idx += 1\n",
    "\n",
    "    # --- RMSE ---\n",
    "    if 'train_rmse' in history and 'val_rmse' in history:\n",
    "        plt.subplot(1, n_metrics, fig_idx)\n",
    "        plt.plot(history['train_rmse'], label='Train RMSE', color='blue')\n",
    "        plt.plot(history['val_rmse'], label='Val RMSE', color='orange')\n",
    "        plt.title('Courbe de RMSE')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('RMSE')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73708cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 2Ô∏è‚É£ Pr√©diction vs R√©alit√© pour une s√©quence\n",
    "# -------------------------------\n",
    "def plot_pred_vs_true_torch(y_true, y_pred, seq_index=0, target=0):\n",
    "    y_true = y_true.cpu().numpy()\n",
    "    y_pred = y_pred.cpu().numpy()\n",
    "\n",
    "    true_seq = y_true[seq_index, :, target]\n",
    "    pred_seq = y_pred[seq_index, :, target]\n",
    "\n",
    "    # masque padding\n",
    "    mask = true_seq != 0\n",
    "    true_seq = true_seq[mask]\n",
    "    pred_seq = pred_seq[mask]\n",
    "\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    plt.plot(true_seq, label='Vraie r√©activit√©', color='green')\n",
    "    plt.plot(pred_seq, label='Pr√©diction', color='red', alpha=0.7)\n",
    "    plt.title(f\"R√©activit√© r√©elle vs pr√©dite ‚Äî S√©quence {seq_index} ‚Äî Target {target}\")\n",
    "    plt.xlabel(\"Position\")\n",
    "    plt.ylabel(\"R√©activit√©\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55978415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 3Ô∏è‚É£ Distribution globale des erreurs\n",
    "# -------------------------------\n",
    "def plot_error_distribution_torch(y_true, y_pred, bins=100):\n",
    "    \"\"\"\n",
    "    Affiche la distribution des erreurs (y_pred - y_true) pour PyTorch tensors.\n",
    "    \n",
    "    y_true : tensor (batch ou dataset)\n",
    "    y_pred : tensor (batch ou dataset)\n",
    "    bins   : nombre de bins pour l'histogramme\n",
    "    \"\"\"\n",
    "    # Convertir en numpy et flatten\n",
    "    y_true = y_true.detach().cpu().numpy().flatten()\n",
    "    y_pred = y_pred.detach().cpu().numpy().flatten()\n",
    "\n",
    "    # Calcul des erreurs\n",
    "    errors = y_pred - y_true\n",
    "\n",
    "    # Supprimer NaN et inf\n",
    "    errors = errors[np.isfinite(errors)]\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.histplot(errors, bins=bins, kde=True, color='purple', stat='density', alpha=0.7)\n",
    "    plt.title('Distribution des erreurs (y_pred - y_true)')\n",
    "    plt.xlabel('Erreur')\n",
    "    plt.ylabel('Densit√©')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb4da20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 4Ô∏è‚É£ Heatmap sur plusieurs s√©quences\n",
    "# -------------------------------\n",
    "def plot_heatmap_sequences_torch(y, n_sequences=30, target=0, title=\"R√©activit√©\", annot=False, fmt=\".2f\"):\n",
    "    \"\"\"\n",
    "    Affiche un heatmap des s√©quences pour un target donn√©.\n",
    "\n",
    "    y           : tensor PyTorch [batch, seq_len, n_targets]\n",
    "    n_sequences : nombre de s√©quences √† afficher\n",
    "    target      : index de la dimension target √† afficher\n",
    "    title       : titre du graphique\n",
    "    annot       : afficher les valeurs sur le heatmap\n",
    "    fmt         : format d'affichage si annot=True\n",
    "    \"\"\"\n",
    "    # Conversion en numpy\n",
    "    y = y.detach().cpu().numpy()\n",
    "\n",
    "    # V√©rification du target\n",
    "    n_targets = y.shape[2]\n",
    "    if target >= n_targets:\n",
    "        raise ValueError(f\"Target {target} est hors limite (n_targets={n_targets})\")\n",
    "\n",
    "    # S√©lection des s√©quences\n",
    "    subset = y[:n_sequences, :, target]\n",
    "\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    sns.heatmap(subset, cmap=\"viridis\", cbar=True, annot=annot, fmt=fmt)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Position\")\n",
    "    plt.ylabel(\"S√©quence\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320fc206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Courbes Loss / MAE / RMSE\n",
    "plot_training_history_torch(\n",
    "    train_losses=history['train_loss'],\n",
    "    val_losses=history['val_loss'],\n",
    "    train_maes=history['train_mae'],\n",
    "    val_maes=history['val_mae'],\n",
    "    train_rmses=history['train_rmse'],\n",
    "    val_rmses=history['val_rmse']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1567600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîπ Mettre le mod√®le en mode √©valuation\n",
    "model.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_trues = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_x, batch_y in test_loader:\n",
    "        batch_x = batch_x.to(device).float()\n",
    "        batch_y = batch_y.to(device).float()\n",
    "        \n",
    "        outputs = model(batch_x)\n",
    "        \n",
    "        all_preds.append(outputs.cpu())\n",
    "        all_trues.append(batch_y.cpu())\n",
    "\n",
    "# Concat√©ner tous les batches\n",
    "y_pred = torch.cat(all_preds, dim=0)\n",
    "y_true = torch.cat(all_trues, dim=0)\n",
    "\n",
    "# Cr√©er le masque pour ignorer les padding si n√©cessaire\n",
    "mask = create_mask(y_true) if 'create_mask' in globals() else torch.ones_like(y_true)\n",
    "mask = mask.bool()\n",
    "\n",
    "# Appliquer le masque\n",
    "y_pred_masked = y_pred[mask]\n",
    "y_true_masked = y_true[mask]\n",
    "\n",
    "# üîπ Calcul des m√©triques sur le jeu test\n",
    "mse = torch.mean((y_pred_masked - y_true_masked)**2).item()\n",
    "mae = torch.mean(torch.abs(y_pred_masked - y_true_masked)).item()\n",
    "rmse = torch.sqrt(torch.tensor(mse)).item()\n",
    "\n",
    "print(f\"Test MSE: {mse:.4f}\")\n",
    "print(f\"Test MAE: {mae:.4f}\")\n",
    "print(f\"Test RMSE: {rmse:.4f}\")\n",
    "\n",
    "# üîπ Visualisations avec les fonctions d√©finies\n",
    "plot_pred_vs_true_torch(y_true, y_pred, seq_index=0, target=0)\n",
    "plot_error_distribution_torch(y_true, y_pred)\n",
    "plot_heatmap_sequences_torch(y_pred, n_sequences=30, target=0, title=\"Pr√©dictions sur Test\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
